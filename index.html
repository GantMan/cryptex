<!DOCTYPE html>
<html>
  <head>
    <link rel="stylesheet" href="styles.css" />
    <!-- Require the peer dependencies of pose-detection. -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>

    <!-- You must explicitly require a TF.js backend if you're not using the TF.js union bundle. -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
    <script>
      const model = poseDetection.SupportedModels.BlazePose
      const detectorConfig = {
        runtime: 'tfjs',
        enableSmoothing: false, // true in video
        modelType: 'full',
      }

      function keypointsToNormalizedKeypoints(keypoints, imageSize) {
        return keypoints.map((keypoint) => {
          const normalizedKeypoint = {
            ...keypoint,
            x: keypoint.x / imageSize.width,
            y: keypoint.y / imageSize.height,
          }

          if (normalizedKeypoint.z != null) {
            // Scale z the same way as x (using image width).
            normalizedKeypoint.z = normalizedKeypoint.z / imageSize.width
          }

          return normalizedKeypoint
        })
      }

      async function runCode() {
        const detector = await poseDetection.createDetector(
          model,
          detectorConfig
        )
        const poseImage = document.getElementById('poseImage')
        const poseImage2 = document.getElementById('poseImage2')
        const firstTA = document.getElementById('firstTA')
        const secondTA = document.getElementById('secondTA')

        const img = tf.browser.fromPixels(poseImage)
        const img2 = tf.browser.fromPixels(poseImage2)
        const estimationConfig = { flipHorizontal: false } // true in video
        const timestamp = performance.now()
        const poses1 = await detector.estimatePoses(
          img,
          estimationConfig,
          timestamp
        )
        const poses2 = await detector.estimatePoses(
          img2,
          estimationConfig,
          timestamp
        )

        const normalized1 =
          //poseDetection.calculators.keypointsToNormalizedKeypoints(
          keypointsToNormalizedKeypoints(poses1[0].keypoints, {
            height: img.shape[0],
            width: img.shape[1],
          })

        const normalized2 =
          //poseDetection.calculators.keypointsToNormalizedKeypoints(
          keypointsToNormalizedKeypoints(poses2[0].keypoints, {
            height: img2.shape[0],
            width: img2.shape[1],
          })

        firstTA.innerHTML = normalized1
          .map((pose) => JSON.stringify(pose, null, 2))
          .join('\n')
        secondTA.innerHTML = normalized2
          .map((pose) => JSON.stringify(pose, null, 2))
          .join('\n')
      }
    </script>
  </head>
  <body>
    <h1>Researching BlazePose</h1>
    <div class="poseGroup">
      <img
        id="poseImage"
        src="./exercise4.jpg"
        alt="first pose image"
        style="max-width: 25%; object-fit: scale-down"
      />
      <textarea id="firstTA" spellcheck="false"></textarea>
      <div id="sizer">
        <img
          id="poseImage2"
          src="./exercise4.jpg"
          alt="second pose image"
          style="max-width: 50%"
        />
      </div>
      <textarea id="secondTA" spellcheck="false"></textarea>
    </div>

    <div id="controls">
      <button onclick="runCode()">Process Images</button>
    </div>
  </body>
</html>
